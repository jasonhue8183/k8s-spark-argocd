apiVersion: argoproj.io/v1alpha1
kind: Workflow
metadata:
  generateName: spark-kubernetes-dag
spec:
  entrypoint: sparkling-operator
  serviceAccountName: spark
  templates:
  - name: sparkpi
    resource: 
      action: create 
      successCondition: status.applicationState.state in (COMPLETED)
      failureCondition: 'status.applicationState.state in (FAILED, SUBMISSION_FAILED, UNKNOWN)'
      manifest: | 
        apiVersion: "sparkoperator.k8s.io/v1beta2"
        kind: SparkApplication
        metadata:
          generateName: spark-pi
        spec:
          type: Scala
          mode: cluster
          image: "gcr.io/spark-operator/spark:v3.0.0"
          imagePullPolicy: Always
          mainClass: org.apache.spark.examples.SparkPi
          mainApplicationFile: "local:///opt/spark/examples/jars/spark-examples_2.12-3.0.0.jar"
          sparkVersion: "3.0.0"
          restartPolicy:
            type: Never
          volumes:
            - name: "test-volume"
              hostPath:
                path: "/tmp"
                type: Directory
          driver:
            cores: 1
            coreLimit: "1200m"
            memory: "512m"
            labels:
              version: 3.0.0
            serviceAccount: spark
            volumeMounts:
              - name: "test-volume"
                mountPath: "/tmp"
          executor:
            cores: 1
            instances: 1
            memory: "512m"
            labels:
              version: 3.0.0
            volumeMounts:
              - name: "test-volume"
                mountPath: "/tmp"
  - name: sparkling-operator
    dag:
      tasks:
      - name: SparkPi1
        template: sparkpi
      - name: SparkPi2
        dependencies: [SparkPi1]
        template: sparkpi
      - name: SparkPi3
        dependencies: [SparkPi1]
        template: sparkpi
